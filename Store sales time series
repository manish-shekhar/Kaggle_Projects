# import important libraries

import calendar
import datetime
from datetime import timedelta
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split,GridSearchCV,StratifiedKFold
import random
from sklearn.metrics import mean_squared_error
import statsmodels.api as sm

from sklearn.linear_model import LogisticRegression,LinearRegression
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, accuracy_score
from sklearn.naive_bayes import GaussianNB
from xgboost import XGBClassifier
import xgboost as xgb
from sklearn.feature_selection import SelectFromModel
from catboost import CatBoostClassifier
from sklearn import preprocessing
from ipywidgets import interact
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder,LabelEncoder
from sklearn.neighbors import KNeighborsClassifier
from fancyimpute import KNN, IterativeImputer
from sklearn.preprocessing import OrdinalEncoder
from sklearn.impute import IterativeImputer, SimpleImputer
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from lightgbm import LGBMClassifier

from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.arima.model import ARIMA
import statsmodels.api
from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess
import lightgbm as lgb


# function to summarise dataframe

def rstr(df):
    counts = df.apply(lambda x: x.count()).values
    uniques = df.apply(lambda x: x.unique()).values
    unique_count = [len(uniques[i]) for i in range(len(uniques))]
    na_val = df.apply(lambda x: x.isna().sum()).values
    na_perc = na_val/len(df)
    data_type = df.dtypes
    mean = df.apply(lambda x:x.mean() if x.dtypes in ['int64','float64','datetime64[ns]'] else 'NaN')
    std_dev = df.apply(lambda x:np.std(x) if x.dtypes in ['int64','float64','datetime64[ns]'] else 'NaN')
    quantile_25 = df.apply(lambda x: x.quantile(0.25) if x.dtypes in ['int64','float64','datetime64[ns]'] else 'NaN')
    quantile_75 = df.apply(lambda x: x.quantile(0.75) if x.dtypes in ['int64','float64','datetime64[ns]'] else 'NaN')
    min_val = df.apply(lambda x: x.min() if x.dtypes in ['int64','float64','datetime64[ns]'] else 'NaN')
    max_val = df.apply(lambda x: x.max() if x.dtypes in ['int64','float64','datetime64[ns]'] else 'NaN')
    d = pd.DataFrame({'counts': counts,'uniques':uniques,
                      'na_val':na_val,'Na_perc':na_perc,'data_type':data_type,
                      'mean':mean,'std_dev':std_dev,'Q25': quantile_25,'Q75':quantile_75,
                      'min':min_val,'max':max_val,'uniques_counts':unique_count},
                     index = df.columns)
    return d
    

# load data

train_df = pd.read_csv('train.csv')
test_df = pd.read_csv('test.csv')
oil = pd.read_csv('oil.csv')
holidays_events = pd.read_csv('holidays_events.csv')
stores = pd.read_csv('stores.csv')
transactions = pd.read_csv('transactions.csv')

combine = pd.concat([train_df, test_df], axis=0, join="outer")


def encode_dates(df,column):
    df=df.copy()
    df[column] = pd.to_datetime(df[column])
    df[column + '_year'] = df[column].apply(lambda x : x.year)
    df[column + '_month'] = df[column].apply(lambda x : x.month)
    df[column + '_day'] = df[column].apply(lambda x : x.day)
    df = df.drop(column, axis=1)
    return df

def convert_dates(df,column):
    df=df.copy()
    df[column] = pd.to_datetime(df[column])
    return df

def ohe(df,column):
    df=df.copy()
    dummies = pd.get_dummies(df[column],prefix=column)
    df = pd.concat([df,dummies],axis=1)
    df = df.drop(column, axis=1)
    return df   

    
# convert to datetime in all

combine = convert_dates(combine,'date')
oil = convert_dates(oil,'date')
holidays_events = convert_dates(holidays_events,'date')
transactions = convert_dates(transactions,'date')


# change oil price column name

oil.loc[:,'dop'] = oil.loc[:,'dcoilwtico']
oil = oil.drop(['dcoilwtico'],axis=1)

# complete all dates and oil proces in oil

start = datetime.datetime.strptime("01-01-2013", "%d-%m-%Y")
complete_dates = pd.DataFrame(pd.date_range(start, periods=(datetime.datetime.strptime("01-09-2017", "%d-%m-%Y") - 
                                                            datetime.datetime.strptime("01-01-2013", "%d-%m-%Y")).days),
                              columns=['date'])


oil = complete_dates.merge(oil, on='date', how='left')

# fill oil price na values

na_index=oil.loc[oil.dop.isna()].index

for index in na_index:
    
    if index == oil.dop.index[0]:
        oil.loc[index,'dop'] = oil.loc[oil.loc[:,'dop'].first_valid_index(),'dop']
        
    else:
        prec_valid_index = oil.loc[oil.dop.index[0] : index,'dop'].last_valid_index()
        succ_valid_index = oil.loc[index : oil.dop.index[-1],'dop'].first_valid_index()
        oil.loc[index,'dop'] = (oil.loc[prec_valid_index,'dop'] + oil.loc[succ_valid_index,'dop'])/2


combine = combine.merge(oil, on='date', how='left')
combine = combine.merge(stores, on='store_nbr', how='left')

# combine family as a family_groups columns

sales_means = combine.groupby('family').mean().sales

combine.loc[:,'family_groups'] = combine.loc[:,'family'].apply(lambda x : 'high_sellers' if sales_means[x]>=700 
                                                        else 'medium_sellers' if sales_means[x]>=100 else 'low_sellers')

